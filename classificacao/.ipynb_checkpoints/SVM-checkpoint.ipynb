{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a22688",
   "metadata": {},
   "source": [
    "### conceito\n",
    "\n",
    "Os **Support Vector Classifiers** são classificadores que funcionam com base na distância de observações próximas ao liminar a ser definido.\n",
    "\n",
    "A distância mais curta entre as observações e o limiar é chamada de **margem**, e o objetivo do SVM vai ser maximizar essa margem. Em alguns casos, a fim de evitar que o limiar seja afetado por outliers, permite-se que estes sejam classificados de forma errada (misclassification). Neste caso, a margem é chamada de **soft margin**. As observações no limite do limiar e dentro deste, em caso de soft margin, são chamadas de **vetores de suporte**, de onde vem o nome **Support Vector Classifier**.\n",
    "\n",
    "Para lidar com conjunto de dados que não são linearmente separáveis a princípio, existe o **Support Vector Machine**. O SVM funciona criando uma dimensão superior à dimensão dos dados, de forma que os dados sejam linearmente separáveis por um SVC considerando esta nova dimensão. O SVC na dimensão superior é encontrado utlizando o **kernel**:\n",
    "\n",
    "- **polynomial kernel**: adiciona *d* graus às observações e calcula a relação de uma com as outra na nova dimensão. \n",
    "- **radial kernel**: calcula as relações em infinitas dimensões (como se zerasse o coeficiente do polinômio e somasse infinitos polinômios de graus diferentes), dando mais \"peso\" aos valores mais próximos ao dado em questão, como se fosse um KNN\n",
    "\n",
    "Pelo fato de calcular as relações como se elas estivessem em uma dimensão superior sem necessariamente transformar os dados para uma dimensão superior, recebem o nome de **kernel trick**.\n",
    "\n",
    "No scikit-learn, dois hiper-parâmetros são importantes:o *c*, que é sobre a regularização do algoritmo, isto é, o quanto a margem poderá ser \"soft\" e permitir misclassification, e o *gamma*, que é sobre o peso que é dado a cada ponto do dataset, isto é, se o valor for alto(?), todos os pontos do dataset serão considerados, de modo que o modelo tenha overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e936061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89162378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Labels:  ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(\"Features: \", cancer.feature_names)\n",
    "\n",
    "print(\"Labels: \", cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3f48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b560c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579f35b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.9811320754716981\n",
      "Recall: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f092bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9811320754716981\n",
      "Recall: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4f78e",
   "metadata": {},
   "source": [
    "#### modelo svc simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91b9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f55ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel = 'linear')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a482e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict([[0,6]])\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
